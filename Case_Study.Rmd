---
title: "Case Study Implementation"
author: "A Companion to Interim Monitoring of Sequential Multiple Assignment Randomized Trials Using Partial Information"
date: ""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Case Study Evaluation

We present here the following steps to analyze the data from our case study. 
These steps follow the outline of Web Appendix K. 

We begin by loading any relevant libraries and the necessary source files. 

```{r, eval=FALSE}
#### source functions ####
library(dplyr)
library(foreach)
library(doParallel)

# source scripts 
for (file in list.files("./value_estimator", pattern=".R")){
  source(paste0("./value_estimator/", file)) # these include the data settings
}
# keep main.R out of this on the server. 
for (file in list.files("./simulation_code", pattern=".R")){
  source(paste0("./simulation_code/", file)) # these include the data settings
}
```

## State the Regimes

We use binary encoding of $0,1$ for all treatment effects. 
When multiple treatments are possible, a vector is given where the first entry corresponds to the response variable $0$ encoding, and the second entry corresponds to the response variable encoding $1$.

We encode treatments to follow the order given in the paper. 
Regime 1 gives treatment $0$ at onset, and treatment $0$ to non-responders, and treatment $0$ to responders. 
Regime 2 gives treatment $0$ at onset, and treatment $0$ to non-responders, and treatment $1$ to responders. 

Based on this, response status of $0$ encodes a yes, and response status of $1$ encodes a no. 
Treatment $0$ at stage $1$ is PCST-Full. For individuals who received PCST-Full, treatment $0$ for non-responders is PCST-Plus and treatment $1$ is Maintenance. 
For individuals who received PCST-Full, treatment $0$ for responders is Maintenance and treatment $1$ is No Intervention. 

We provide a function that when given a list of regimes encoded as described and a data set, maps the treatments to their respective regime number. 
This provides indicators for the regime and regime consistency. 

We also set the `feasibleSetsIndicator` to FALSE to indicate that there are no deterministic treatments based on a response status. 


```{r, eval=FALSE}
regimes <- list(list(0,c(0,0)),
                list(0,c(0,1)),
                list(0,c(1,0)),
                list(0,c(1,1)),
                list(1,c(0,0)),
                list(1,c(0,1)),
                list(1,c(1,0)),
                list(1,c(1,1)))
feasibleSetsIndicator=FALSE
steps <- 2  # provides the number of decisions in the regime

regimelist_case_study <- function(embRegimes, dat){
  regime_list <- list()
  nRegimes <- length(embRegimes)
  n <- nrow(dat)
  K <- length(embRegimes[[1]])
  
  for(r in c(1:nRegimes)){
    regime <- matrix(NA, nrow=n, ncol=K)
    regime_ind <- matrix(NA, nrow=n, ncol=K)
    
    regimen <- embRegimes[[r]]
    for (k in 1:K){
      if (paste0("r", k) %in% colnames(dat)) {
        # then we have trt for non respond followed by trt for resp
        regime[,k] <- regimen[[k]][1]*(1-dat[,paste0("r", k)]) + 
          regimen[[k]][2]*(dat[,paste0("r", k)])
        
      } else{
        regime[,k] <- regimen[[k]]
      }
      
      regime_ind[,k] <- (dat[, paste0('a',k)] == regime[,k])*1
      
      
    }
    colnames(regime) <- paste0('regime', 1:K)
    colnames(regime_ind) <- paste0('a', 1:K, '_ind')  
    
    regime_list[[r]] <- list('regime' = regime,
                             "regime_ind" = regime_ind)
  }
  return(regime_list)
}
```

## Posit models 

We posit using simple means to estimate the proportions of individuals at each stage of the trial at interim analyses. 
These models are the default within the available code. 
To use more complex models, a user will need to update the files `nu.R` and the associated estimating equations for variance calculations in `ee_nu.R` and `ee_value_derivatives.R`.
We use the modelObj package to keep our method of model specification consistent with the available DynTxRegime package available in CRAN. 


```{r, eval=FALSE}
q2 <- modelObj::buildModelObj(model = ~ x11 + x12 + x13 + x14 + x15 +x20 + x21 +
                                a1 + a2 + a1:a2 + r2 + a1:r2,
                              solver.method = 'lm',
                              predict.method = 'predict.lm')
q1 <- modelObj::buildModelObj(model = ~ x11 + x12 + x13 + x14 + x15 +
                                a1,
                              solver.method = 'lm',
                              predict.method = 'predict.lm')
q_list <- list(q1, q2)


p1 <- modelObj::buildModelObj(model = ~ 1,
                              solver.method = 'glm',
                              solver.args = list(family='binomial'),
                              predict.method = 'predict.glm',
                              predict.args = list(type='response'))

p2 <- modelObj::buildModelObj(model = ~ I(a1==0):I(r2==0) -1,
                              solver.method = 'glm',
                              solver.args = list(family='binomial'),
                              predict.method = 'predict.glm',
                              predict.args = list(type='response'))

pi_list <- list(p1, p2)
```

## Choose the number of analyses and when they occur

For our case study, we have chosen to consider $2$ analyses, the first at day $500$ and the second at the end of the trial. 

```{r, eval=FALSE}
t_s_list = list(500, TRUE)  # when to perform analyses, TRUE means do a final analyses
```

## Estimate the variance

We chose to estimate the variance numerically for determining boundaries for our study. 

This requires positing the distributions of the coefficients. 
We define a function for generating data similar to what we expect for the data set from the case study. 

Depending the version of `R` and the initial seed, there may be some slight variability in the estimted variance. 

We provide the function `estimateVariances` in the simulation code. 
It takes a function that returns a sample data set for a given sample size and value pattern, the function that returns regime consistency, the regimes of interest, 
the specified models, and the information about when the analyses are to occur. 
The variances will be written to the file directory passed to the function and the job parallelized over the number of cores specified. 
The parameter delta refers to the difference between the regime value estimates and the null hypothesis. 

Depending on the number of bootstrap samples requested and cores available, this process may take over ten minutes. 

```{r, eval=FALSE}

design_case_study <- function(vp, n, seed=1, s2=900, a1p=0.5, a2p=0.5, r2p = 0.5){
  set.seed(seed)
  # get the parameter values associated with the value pattern given by user
  if (vp==1){
    # to vary x higher, use 0.02, 3, 3
    vpbeta <- c(-9, c(0, 0.2, 0, 10, -10), c(1), c(0), c(0, 0, 0), c(0, 0, 0))  # all equal to 22.5
  } else if (vp==2) {
    vpbeta <- c(1, c(0, 0.2, 0, 10, -10), c(1), c(0), c(-10, 0, 0), c(0, 0, 0))  # power a1=0 higher by 10
  } else if (vp==3) {
    vpbeta <- c(1, c(0, 0.2, 0, 10, -10), c(1), c(0), c(-10, -5, -2), c(10, -2, 0))
  }

  y1 <- as.integer(runif(n, min=50, max=101))/10 
  
  # randomly assign treatments to each individual
  a1 <- rbinom(n=n, size=1, prob=a1p)
  x11 <- rnorm(n=n, mean=152, sd=5) # height mean 152cm (~5ft), sd=5
  x12 <- rnorm(n=n, mean=55, sd=10)  # weight mean 55kg (~120lbs), sd=10
  x13 <- rbinom(n=n, size=1, p=0.65) # presence of comorbidities, maybe hypertension
  x14 <- rbinom(n=n, size=1, p=0.40) # use of pain medications (set at 40%)
  x15 <- rbinom(n=n, size=1, p=0.60) # if they received chemotherapy
  
  r2 <- rbinom(n=n, size=1, p=r2p)
  a2 <- rbinom(n=n, size=1, prob=a2p)
  # time 2 reduction for responders vs. non-responders
  red2 <- runif(n=n, min=30, max=40)*(1-r2) + runif(n=n, min=0, max=20)*(r2)  # reduction as percent at time2
  pain2 <- round(y1 * (1-red2/100), 1)
  # to check see summary((y1 - pain2) / y1)
  
  # adherence
  x21 <- runif(n=n, min=0.5, max=1)  # therapist adherence
  
  # errors in the reduction observed
  ei <- rnorm(n=n, mean=0, sd=sqrt(s2))
  
  # final reduction
  red3 <- cbind(1, x11, x12, x13, x14, x15, red2, x21, a1, a2, a1*a2, r2, a1*r2, a1*a2*x13) %*% 
    vpbeta  + ei
  
  # final y
  y3 <- round(y1 * (1-red3/100), 1)
  
  # create the times of arrival for patients
  # these are done using the fixed times given to control for variance due
  # to enrollment process.
  # We multiple the process by 1000 to have the unit be 'days'.
  t1 <- round(runif(n, 0, 1), 3)*1000
  t2 <- t1 + 56 # round(runif(n, min=35, max=57)) # 8 weeks
  t3 <- t2 + 126 # round(runif(n, min=35, max=57)) + round(runif(n, min=150, max=210)) # 18 weeks later
  dat <- as.data.frame(cbind(round(red3, 1), round(x11), round(x12,1), x13, x14, x15, round(red2,1), 
                             round(x21,1), a1, a2, r2, t1, t2, t3))
  names(dat)[1] <- "y"
  names(dat)[2] <- "x11"
  names(dat)[3] <- "x12"
  names(dat)[7] <- "x20"
  names(dat)[8] <- "x21"
  
  return(dat)
}

vp_var <- 1
nvars <- 500
ncores <- 1
delta <- rep(22.5, 8)
filedir <- "./"
Bvars <- 100

estimateVariances(makeData = design_case_study, vp=vp_var, n=nvars, regime_fn= regimelist_case_study,
                  regimes= regimes,
                  loops=Bvars, q_list=q_list, pi_list=pi_list,
                  t_s_list= t_s_list, feasibleSetsIndicator=feasibleSetsIndicator, 
                  cores=ncores,
                  delta = delta, # should match H0
                  out_location=filedir)

```

## Determine the stopping boundaries under a specified alternative

Once the files output from `estimateVariances` are available, the provided function `getBoundaries` will calculate the Pocock and O'Brien-Fleming type stopping boundaries when for a no difference hypothesis. 
This function requires the file directory to point to the covariances and the desired type I error rate. 
The boundaries are estimated empirically by performing the multivariate integration of the asymptotic normal distribution. 

```{r, eval=FALSE}
getBoundaries(filedir, alpha=alpha)
bounds <- rlist::list.load(paste0(filedir, "/stoppingBoundaries.Rdata"))
```


## Perform analyses

The function `IAIPW` takes an integer time and evaluates the estimator using data that is marked as available at that time. 
This allows us to avoid restrictions on how missing values are encoded. 
To obtain estimates for the IPWE and AIPWE, we can subset our data frame to contain only the individuals who had completed the trial at the time of interim analysis.

The function `IAIPW` returns information on all estimated parameters. 
We include a function that will report only the regime-related statistics. 
These summary statistics can be used to calculate the relevant z-statistics which can be compared with the chosen stopping boundaries.

```{r, eval=FALSE}
# IAIPW
pbound <- c(2.66, 2.66)
ofbound <- c(4.20, 2.43)

# complete case AIPW
pbound_aipw <- c(2.66, 2.66)
ofbound_aipw <- c(4.30, 2.44)

# complete case IPW
pbound_ipw <- c(2.66, 2.66)
ofbound_ipw <- c(4.30, 2.44)

N <- 284  # this is based on the effective sample size for the cancer trial. 

df <- read.csv("./case_study_data.csv", row.names=1)
regime_all <- regimelist_case_study(embRegimes = regimes,
                        dat = df)

df_cc <- df[df$t3 <= 500,]
regime_all_cc <- regimelist_case_study(embRegimes = regimes,
                                    dat = df_cc)

#### IAIPWE ####
t1_res <- IAIPW(df=df, pi_list=pi_list, q_list=q_list, regime_all=regime_all, 
                feasibleSetsIndicator=feasibleSetsIndicator, t_s=500) 
t2_res <- IAIPW(df=df, pi_list=pi_list, q_list=q_list, regime_all=regime_all, 
                feasibleSetsIndicator=feasibleSetsIndicator, t_s=max(df$t3)) 

#### IPWE ####
t1_resi <- IAIPW(df=df_cc, pi_list=pi_list, q_list=NULL, regime_all=regime_all_cc, 
                feasibleSetsIndicator=feasibleSetsIndicator, t_s=500) 
t2_resi <- IAIPW(df=df, pi_list=pi_list, q_list=NULL, regime_all=regime_all, 
                feasibleSetsIndicator=feasibleSetsIndicator, t_s=max(df$t3)) 

#### AIPWE ####
t1_resa <- IAIPW(df=df_cc, pi_list=pi_list, q_list=q_list, regime_all=regime_all_cc, 
                feasibleSetsIndicator=feasibleSetsIndicator, t_s=500) 
t2_resa <- IAIPW(df=df, pi_list=pi_list, q_list=q_list, regime_all=regime_all, 
                feasibleSetsIndicator=feasibleSetsIndicator, t_s=max(df$t3)) 

#### Unpack results ####

unpack_IAIPW <- function(res){
  L <- length(res$values)
  n <- res$nus$ns
  endi <- dim(res$covariance)[2]
  starti <- endi - L + 1
  cov_ <- res$covariance[starti:endi, starti:endi]
  se_ <- sqrt(diag(cov_) / n)
  
  return( list('value' = res$values,
               'variance' = cov_,
               'se' = se_,
               'n' = n))
}

#### IAIPWE ####
t1_sum <- unpack_IAIPW(t1_res)
z1 <- (t1_sum$value - delta) / t1_sum$se  # z-statistics

t2_sum <- unpack_IAIPW(t2_res)
z2 <- (t2_sum$value - delta) / t2_sum$se  # z-statistics

#### IPWE ####
t1_sum <- unpack_IAIPW(t1_resi)
z1 <- (t1_sum$value - delta) / t1_sum$se  # z-statistics

t2_sum <- unpack_IAIPW(t2_resi)
z2 <- (t2_sum$value - delta) / t2_sum$se  # z-statistics

#### AIPWE ####
t1_sum <- unpack_IAIPW(t1_resa)
z1 <- (t1_sum$value - delta) / t1_sum$se  # z-statistics

t2_sum <- unpack_IAIPW(t2_resa)
z2 <- (t2_sum$value - delta) / t2_sum$se  # z-statistics
```



## Check the information proportions

The information proportions can be checked using the standard errors obtained from the output. 
Practicioners should remember that for small $n$, the information proportion may be smaller than expected based on the asymptotic distribution. 
In such cases, the stopping boundaries are more conservative. 

























